{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1271632,"sourceType":"datasetVersion","datasetId":732786}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport librosa\n\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\nfrom sklearn.preprocessing import label_binarize\n\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom torch.nn import CrossEntropyLoss\nfrom torch.utils.data import DataLoader, Dataset, random_split\n\nfrom skimage.transform import resize\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport timm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T14:50:30.672438Z","iopub.execute_input":"2024-12-17T14:50:30.673975Z","iopub.status.idle":"2024-12-17T14:50:40.165173Z","shell.execute_reply.started":"2024-12-17T14:50:30.673931Z","shell.execute_reply":"2024-12-17T14:50:40.164196Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/bird-song-data-set/bird_songs_metadata.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T14:50:40.166694Z","iopub.execute_input":"2024-12-17T14:50:40.16697Z","iopub.status.idle":"2024-12-17T14:50:40.244058Z","shell.execute_reply.started":"2024-12-17T14:50:40.166943Z","shell.execute_reply":"2024-12-17T14:50:40.24306Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"species_counts = df['species'].value_counts()\nprint(species_counts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T14:50:40.245256Z","iopub.execute_input":"2024-12-17T14:50:40.245589Z","iopub.status.idle":"2024-12-17T14:50:40.264263Z","shell.execute_reply.started":"2024-12-17T14:50:40.245561Z","shell.execute_reply":"2024-12-17T14:50:40.262965Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T14:50:40.266816Z","iopub.execute_input":"2024-12-17T14:50:40.267243Z","iopub.status.idle":"2024-12-17T14:50:40.281537Z","shell.execute_reply.started":"2024-12-17T14:50:40.267215Z","shell.execute_reply":"2024-12-17T14:50:40.280621Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# bngeb al len bta3 al audio\ndef len_audio(path,sample_rate=16000):\n    file_path = \"/kaggle/input/bird-song-data-set/wavfiles/\" + path\n    audio ,sr= librosa.load(file_path,sr=None)\n    audio_len = len(audio) / sr\n    return audio_len","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T14:50:40.282628Z","iopub.execute_input":"2024-12-17T14:50:40.282957Z","iopub.status.idle":"2024-12-17T14:50:40.287978Z","shell.execute_reply.started":"2024-12-17T14:50:40.282904Z","shell.execute_reply":"2024-12-17T14:50:40.287045Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['audio_length'] = df['filename'].apply(len_audio)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T14:50:40.288843Z","iopub.execute_input":"2024-12-17T14:50:40.289074Z","iopub.status.idle":"2024-12-17T14:51:49.449099Z","shell.execute_reply.started":"2024-12-17T14:50:40.289051Z","shell.execute_reply":"2024-12-17T14:51:49.448326Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# bshof al length bta3 al audio mo5tlf wala eh\ndf['audio_length'].hist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T14:51:49.45036Z","iopub.execute_input":"2024-12-17T14:51:49.450877Z","iopub.status.idle":"2024-12-17T14:51:49.719499Z","shell.execute_reply.started":"2024-12-17T14:51:49.450849Z","shell.execute_reply":"2024-12-17T14:51:49.718588Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# b load al audio :)\ndef load_audio(path,target_rate = 16000):\n    file_path = file_path = \"/kaggle/input/bird-song-data-set/wavfiles/\" + path\n    \n    audio,sr = librosa.load(file_path,sr=None)\n\n    audio = librosa.resample(audio, orig_sr=sr, target_sr=target_rate)\n\n    audio = np.array(audio)\n    return audio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T14:51:49.720642Z","iopub.execute_input":"2024-12-17T14:51:49.720886Z","iopub.status.idle":"2024-12-17T14:51:49.725849Z","shell.execute_reply.started":"2024-12-17T14:51:49.720861Z","shell.execute_reply":"2024-12-17T14:51:49.725007Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['audio'] = df['filename'].apply(load_audio)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T14:51:49.72686Z","iopub.execute_input":"2024-12-17T14:51:49.727111Z","iopub.status.idle":"2024-12-17T14:52:06.030582Z","shell.execute_reply.started":"2024-12-17T14:51:49.727087Z","shell.execute_reply":"2024-12-17T14:52:06.029488Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_audio_to_mel_log_spectrogram(example, sr=16000, n_mels=128, target_size=(224, 224)):\n    audio = example\n    \n    # Generate Mel spectrogram\n    mel_spec = librosa.feature.melspectrogram(y=np.array(audio), sr=sr, n_mels=n_mels)\n    \n    # Convert to log scale (Mel-log spectrogram)\n    log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n    \n    # Normalize the spectrogram to [0, 1]\n    log_mel_spec -= log_mel_spec.min()\n    log_mel_spec /= log_mel_spec.max()\n    \n    # Resize spectrogram to target size\n    resized_spec = resize(log_mel_spec, target_size, anti_aliasing=True, mode='reflect')\n\n    resized_spec = np.stack([resized_spec] * 3, axis=0)\n    \n    return resized_spec","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T14:52:06.033386Z","iopub.execute_input":"2024-12-17T14:52:06.033677Z","iopub.status.idle":"2024-12-17T14:52:06.039468Z","shell.execute_reply.started":"2024-12-17T14:52:06.033651Z","shell.execute_reply":"2024-12-17T14:52:06.038545Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['mel_log'] = df['audio'].apply(process_audio_to_mel_log_spectrogram)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T14:52:06.040531Z","iopub.execute_input":"2024-12-17T14:52:06.040805Z","iopub.status.idle":"2024-12-17T14:53:44.440574Z","shell.execute_reply.started":"2024-12-17T14:52:06.040778Z","shell.execute_reply":"2024-12-17T14:53:44.43905Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"song_features = df['mel_log'].values\nlabels = pd.get_dummies(df['species']).astype(np.float32).values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T14:53:44.442193Z","iopub.execute_input":"2024-12-17T14:53:44.443123Z","iopub.status.idle":"2024-12-17T14:53:44.460833Z","shell.execute_reply.started":"2024-12-17T14:53:44.443054Z","shell.execute_reply":"2024-12-17T14:53:44.459066Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class birdset(Dataset):\n    def __init__(self,features,labels):\n        self.features = features\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self,idx):\n        feature = self.features[idx]\n        label = self.labels[idx]\n        return torch.tensor(feature),torch.tensor(label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T14:53:44.46313Z","iopub.execute_input":"2024-12-17T14:53:44.464522Z","iopub.status.idle":"2024-12-17T14:53:44.476722Z","shell.execute_reply.started":"2024-12-17T14:53:44.464237Z","shell.execute_reply":"2024-12-17T14:53:44.475419Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = birdset(song_features,labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T14:53:44.478683Z","iopub.execute_input":"2024-12-17T14:53:44.479565Z","iopub.status.idle":"2024-12-17T14:53:44.491062Z","shell.execute_reply.started":"2024-12-17T14:53:44.479489Z","shell.execute_reply":"2024-12-17T14:53:44.489273Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T14:53:44.492414Z","iopub.execute_input":"2024-12-17T14:53:44.492904Z","iopub.status.idle":"2024-12-17T14:53:44.534904Z","shell.execute_reply.started":"2024-12-17T14:53:44.492834Z","shell.execute_reply":"2024-12-17T14:53:44.533679Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"learning_rate = 1e-4\nbatch_size = 64\nepochs = 3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T14:53:44.540121Z","iopub.execute_input":"2024-12-17T14:53:44.540644Z","iopub.status.idle":"2024-12-17T14:53:44.551057Z","shell.execute_reply.started":"2024-12-17T14:53:44.540586Z","shell.execute_reply":"2024-12-17T14:53:44.548072Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T14:53:44.554171Z","iopub.execute_input":"2024-12-17T14:53:44.554686Z","iopub.status.idle":"2024-12-17T14:53:44.565387Z","shell.execute_reply.started":"2024-12-17T14:53:44.554632Z","shell.execute_reply":"2024-12-17T14:53:44.564534Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(model, train_loader, criterion, optimizer, device, epochs=3):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        correct = 0\n        total = 0\n\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            labels = torch.argmax(labels, dim=1)\n\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n        train_accuracy = correct / total\n        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss:.4f}, Accuracy: {train_accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T14:53:44.566356Z","iopub.execute_input":"2024-12-17T14:53:44.566638Z","iopub.status.idle":"2024-12-17T14:53:44.577965Z","shell.execute_reply.started":"2024-12-17T14:53:44.566612Z","shell.execute_reply":"2024-12-17T14:53:44.577188Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\nimport numpy as np\nfrom sklearn.preprocessing import label_binarize\n\ndef evaluate_model(model, val_loader, device, num_classes):\n    model.eval()\n    val_correct = 0\n    val_total = 0\n    val_all_labels = []\n    val_all_predictions = []\n    val_all_probs = []\n\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            labels = torch.argmax(labels, dim=1)\n\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            val_total += labels.size(0)\n            val_correct += (predicted == labels).sum().item()\n\n            val_all_labels.extend(labels.cpu().numpy())\n            val_all_predictions.extend(predicted.cpu().numpy())\n            val_all_probs.extend(torch.softmax(outputs, dim=1).cpu().numpy())\n\n    val_accuracy = val_correct / val_total\n    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n\n    # Confusion Matrix\n    val_cm = confusion_matrix(val_all_labels, val_all_predictions)\n    print(f\"Validation Confusion Matrix:\\n{val_cm}\")\n\n    # Precision, Recall, F1 Score\n    val_precision = precision_score(val_all_labels, val_all_predictions, average='weighted')\n    val_recall = recall_score(val_all_labels, val_all_predictions, average='weighted')\n    val_f1 = f1_score(val_all_labels, val_all_predictions, average='weighted')\n\n    print(f\"Validation Precision: {val_precision:.4f}\")\n    print(f\"Validation Recall: {val_recall:.4f}\")\n    print(f\"Validation F1 Score: {val_f1:.4f}\")\n\n    # ROC AUC\n    val_all_labels_bin = label_binarize(val_all_labels, classes=range(num_classes))  # Adjust num_classes\n    val_roc_auc = roc_auc_score(val_all_labels_bin, val_all_probs, multi_class='ovr', average='weighted')\n    print(f\"Validation ROC AUC: {val_roc_auc:.4f}\")\n\n    # ROC Curve Plot\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    \n    for i in range(num_classes):\n        fpr[i], tpr[i], _ = roc_curve(val_all_labels_bin[:, i], np.array(val_all_probs)[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # Plot the ROC curve for each class\n    plt.figure()\n    colors = ['blue', 'red', 'green', 'orange', 'purple']  # Add more colors if needed\n    \n    for i in range(num_classes):\n        plt.plot(fpr[i], tpr[i], color=colors[i % len(colors)], lw=2, label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return val_cm, val_accuracy, val_precision, val_recall, val_f1, val_roc_auc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T14:53:44.578954Z","iopub.execute_input":"2024-12-17T14:53:44.579259Z","iopub.status.idle":"2024-12-17T14:53:44.59551Z","shell.execute_reply.started":"2024-12-17T14:53:44.579232Z","shell.execute_reply":"2024-12-17T14:53:44.594724Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn as nn\n\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(\n                in_channels,\n                out_channels,\n                kernel_size=3,\n                stride=stride,\n                padding=1,\n            ),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n        )\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(out_channels),\n        )\n        self.downsample = downsample\n        self.relu = nn.ReLU()\n        self.out_channels = out_channels\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.conv2(out)\n\n        if self.downsample:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(\n        self,\n        layers,\n        out_neurons=1,\n        block=ResidualBlock,\n    ):\n        super(ResNet, self).__init__()\n        self.inplanes = 64\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n        )\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer0 = self._make_layer(block, 64, layers[0], stride=1)\n        self.layer1 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer2 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer3 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.fc = nn.Linear(512, out_neurons)\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n                nn.BatchNorm2d(planes),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n\n        self.inplanes = planes\n        for _ in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.maxpool(x)\n\n        x = self.layer0(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T14:53:44.596694Z","iopub.execute_input":"2024-12-17T14:53:44.596961Z","iopub.status.idle":"2024-12-17T14:53:44.610638Z","shell.execute_reply.started":"2024-12-17T14:53:44.596936Z","shell.execute_reply":"2024-12-17T14:53:44.609879Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class BottleneckBlock(nn.Module):\n    expansion = 4\n    \n    def __init__(\n        self,\n        in_channels: int,\n        out_channels: int=3,\n        identity_downsample=None,\n        stride: int = 1,\n    ):\n        super(BottleneckBlock, self).__init__()\n        self.identity_downsample = identity_downsample\n\n        self.conv1 = nn.Conv2d(\n            in_channels,\n            out_channels,\n            kernel_size=1,\n            stride=1,\n            padding=0,\n        )\n        self.bn1 = nn.BatchNorm2d(out_channels)\n\n        self.conv2 = nn.Conv2d(\n            out_channels,\n            out_channels,\n            kernel_size=3,\n            stride=stride,\n            padding=1,\n        )\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n        self.conv3 = nn.Conv2d(\n            out_channels,\n            out_channels * self.expansion,\n            kernel_size=1,\n            stride=1,\n            padding=0,\n        )\n        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        identity = x\n\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n\n        x = self.conv3(x)\n        x = self.bn3(x)\n\n        if self.identity_downsample is not None:\n            identity = self.identity_downsample(identity)\n\n        x += identity\n        return self.relu(x)\n\n\nclass DeepResNet(nn.Module):\n    def __init__(\n        self, layers: list, out_neurons: int, image_channels: int=3, block=BottleneckBlock\n    ):\n        super(DeepResNet, self).__init__()\n        self.in_channels = 64\n        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        self.layer1 = self._make_layer(block, layers[0], out_channels=64, stride=1)\n        self.layer2 = self._make_layer(block, layers[1], out_channels=128, stride=2)\n        self.layer3 = self._make_layer(block, layers[2], out_channels=256, stride=2)\n        self.layer4 = self._make_layer(block, layers[3], out_channels=512, stride=2)\n\n        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n        self.flatten = nn.Flatten()\n        self.ffn = nn.Linear(512 * 4, out_neurons)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = self.flatten(x)\n        return self.ffn(x)\n\n    def _make_layer(\n        self,\n        block,\n        num_residual_blocks: int,\n        out_channels: int,\n        stride: int = 1,\n    ):\n        identity_downsample = None\n        layers = []\n\n        if stride != 1 or self.in_channels != out_channels * block.expansion:\n            identity_downsample = nn.Sequential(\n                nn.Conv2d(\n                    self.in_channels,\n                    out_channels * block.expansion,\n                    kernel_size=1,\n                    stride=stride,\n                ),\n                nn.BatchNorm2d(out_channels * block.expansion),\n            )\n\n        layers.append(\n            block(\n                self.in_channels,\n                out_channels,\n                identity_downsample=identity_downsample,\n                stride=stride,\n            )\n        )\n\n        self.in_channels = out_channels * block.expansion\n\n        for _ in range(num_residual_blocks - 1):\n            layers.append(block(self.in_channels, out_channels))\n\n        return nn.Sequential(*layers)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T14:53:44.611855Z","iopub.execute_input":"2024-12-17T14:53:44.612156Z","iopub.status.idle":"2024-12-17T14:53:44.627125Z","shell.execute_reply.started":"2024-12-17T14:53:44.612129Z","shell.execute_reply":"2024-12-17T14:53:44.626512Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_model(model_name, num_classes, pretrained=True):\n    if model_name == 'densenet121':\n        model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet121', pretrained=pretrained)\n        model.classifier = nn.Linear(in_features=1024, out_features=num_classes, bias=True)\n    elif model_name == 'xception':\n        model = timm.create_model('xception', pretrained=pretrained)\n        model.fc = nn.Linear(in_features=model.fc.in_features, out_features=num_classes)\n    elif model_name == 'resnet-18':\n        model = ResNet(layers=[2, 2, 2, 2], out_neurons=num_classes)\n    elif model_name == \"resnet-50\":\n        model = DeepResNet(layers=[3, 4, 6, 3], out_neurons=num_classes, block=BottleneckBlock)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T14:53:44.628068Z","iopub.execute_input":"2024-12-17T14:53:44.628359Z","iopub.status.idle":"2024-12-17T14:53:44.642185Z","shell.execute_reply.started":"2024-12-17T14:53:44.628298Z","shell.execute_reply":"2024-12-17T14:53:44.641475Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compare_models(train_loader, val_loader, device, num_classes, res_epochs=10, tuning_epochs=3):\n    models = [\n        ('densenet121', tuning_epochs),\n        ('xception', tuning_epochs),\n        ('resnet-18', res_epochs),\n        ('resnet-50', res_epochs),\n    ]\n    results = {}\n\n    for model_name, epochs in models:\n        print(f\"\\nTraining and Evaluating {model_name} for {epochs} epochs...\")\n        # Load and initialize the model\n        model = load_model(model_name, num_classes)\n        model.to(device)\n\n        # Define the criterion and optimizer\n        criterion = nn.CrossEntropyLoss()\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n        # Train the model\n        train_model(model, train_loader, criterion, optimizer, device, epochs)\n\n        # Evaluate the model\n        cm, accuracy, precision, recall, f1, roc_auc = evaluate_model(model, val_loader, device, num_classes)\n\n        results[model_name] = {\n            'Confusion Matrix': cm,\n            'Accuracy': accuracy,\n            'Precision': precision,\n            'Recall': recall,\n            'F1 Score': f1,\n            'ROC AUC': roc_auc\n        }\n\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T14:53:44.643481Z","iopub.execute_input":"2024-12-17T14:53:44.643741Z","iopub.status.idle":"2024-12-17T14:53:44.656224Z","shell.execute_reply.started":"2024-12-17T14:53:44.643715Z","shell.execute_reply":"2024-12-17T14:53:44.655471Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nresults = compare_models(train_loader, val_loader, device, num_classes=5, res_epochs=10, tuning_epochs=3)\n\n# Print results\nfor model_name, metrics in results.items():\n    print(f\"\\nResults for {model_name}:\")\n    for metric, value in metrics.items():\n        if metric == 'Confusion Matrix':\n            continue\n        # If value is a NumPy array, handle it based on its size\n        if isinstance(value, np.ndarray):\n            if value.size == 1:\n                value = value.item()  # Converts to a Python scalar if it's a single-element array\n            else:\n                value = np.mean(value)  # Example: take the mean of the array\n        print(f\"{metric}: {value:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T14:53:44.657284Z","iopub.execute_input":"2024-12-17T14:53:44.657626Z","iopub.status.idle":"2024-12-17T15:17:56.036656Z","shell.execute_reply.started":"2024-12-17T14:53:44.657598Z","shell.execute_reply":"2024-12-17T15:17:56.035567Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for model_name, metrics in results.items():\n    cm = metrics['Confusion Matrix']\n    accuracy = metrics['Accuracy']\n    precision = metrics['Precision']\n    recall = metrics['Recall']\n    f1_score = metrics['F1 Score']\n    roc_auc = metrics['ROC AUC']\n\n    # Plot Confusion Matrix\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.title(f'Confusion Matrix - {model_name}')\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T15:17:56.038249Z","iopub.execute_input":"2024-12-17T15:17:56.038684Z","iopub.status.idle":"2024-12-17T15:17:58.13716Z","shell.execute_reply.started":"2024-12-17T15:17:56.038643Z","shell.execute_reply":"2024-12-17T15:17:58.136139Z"}},"outputs":[],"execution_count":null}]}